# СПЕЦИФИКАЦИЯ АЛГОРИТМОВ И СТРУКТУР ДАННЫХ
## Высокопроизводительная Многостадийная Система Маршрутизации Сообщений

**Автор**: Yan Bubenok
**Email**: yan@bubenok.com
**Telegram**: @iBubenok

**Версия**: 1.0
**Дата**: 2025-11-14
**Статус**: Утверждено

---

## 1. СТРУКТУРЫ ДАННЫХ

### 1.1 Message (Сообщение)

**Назначение:** Базовая единица данных, передаваемая через систему.

**Определение:**
```cpp
struct Message {
    // === Основные поля (Producer) ===
    uint8_t msg_type;           // Тип сообщения (0-7)
    uint8_t producer_id;        // ID производителя (0-255)
    uint64_t sequence_number;   // Порядковый номер
    uint64_t timestamp_ns;      // Временная метка создания

    // === Поля обработки (Processor) ===
    uint8_t processor_id;       // ID процессора (0-255)
    uint64_t processing_ts_ns;  // Временная метка обработки

    // === Поля трассировки (Timestamps) ===
    uint64_t stage1_entry_ns;   // Вход в Stage1 Router
    uint64_t stage1_exit_ns;    // Выход из Stage1 Router
    uint64_t processing_entry_ns; // Вход в Processor
    uint64_t processing_exit_ns;  // Выход из Processor
    uint64_t stage2_entry_ns;   // Вход в Stage2 Router
    uint64_t stage2_exit_ns;    // Выход из Stage2 Router

    // === Методы ===
    static Message create(uint8_t type, uint8_t producer_id, uint64_t seq_num);
    static uint64_t get_timestamp_ns();

    double end_to_end_latency_us() const;
    double stage1_latency_us() const;
    double processing_latency_us() const;
    double stage2_latency_us() const;
};

// Проверка типа
static_assert(std::is_trivially_copyable_v<Message>);
```

**Свойства:**
- **Размер**: ~96 байт (1.5 cache lines)
- **Выравнивание**: Естественное (8 байт для uint64_t)
- **Копируемость**: Trivially copyable (POD-тип)
- **Инвариант**: `sequence_number` монотонно возрастает для каждого производителя

**Расчет задержек:**
```cpp
double Message::end_to_end_latency_us() const {
    return (stage2_exit_ns - timestamp_ns) / 1000.0;
}

double Message::stage1_latency_us() const {
    return (stage1_exit_ns - stage1_entry_ns) / 1000.0;
}

double Message::processing_latency_us() const {
    return (processing_exit_ns - processing_entry_ns) / 1000.0;
}

double Message::stage2_latency_us() const {
    return (stage2_exit_ns - stage2_entry_ns) / 1000.0;
}
```

### 1.2 SPSCQueue (Lock-Free Очередь)

**Назначение:** Lock-free очередь для одного производителя и одного потребителя.

**Определение:**
```cpp
template<typename T, size_t Capacity>
class SPSCQueue {
    static_assert((Capacity & (Capacity - 1)) == 0,
                  "Capacity должна быть степенью двойки");
    static_assert(std::is_trivially_copyable_v<T>,
                  "T должен быть trivially copyable");

public:
    SPSCQueue() : head_(0), tail_(0) {}

    bool try_push(const T& item) noexcept;
    bool try_pop(T& item) noexcept;
    bool empty() const noexcept;
    size_t size() const noexcept;
    static constexpr size_t capacity() noexcept;

private:
    alignas(64) std::atomic<size_t> head_;  // Consumer index
    alignas(64) std::atomic<size_t> tail_;  // Producer index
    alignas(64) T buffer_[Capacity];        // Ring buffer
};
```

**Инварианты:**
1. `0 <= head_ < Capacity`
2. `0 <= tail_ < Capacity`
3. Очередь пустая: `head_ == tail_`
4. Очередь полная: `(tail_ + 1) % Capacity == head_`
5. Количество элементов: `(tail_ - head_ + Capacity) % Capacity`

**Complexity:**
- `try_push`: O(1) амортизированная
- `try_pop`: O(1) амортизированная
- `empty`: O(1)
- `size`: O(1)

### 1.3 LatencyStats (Статистика задержек)

**Назначение:** Сбор и вычисление перцентилей задержек.

**Определение:**
```cpp
struct LatencyStats {
    std::vector<double> latencies;  // Собранные значения

    void add(double latency_us);
    void clear();

    double percentile(double p) const;
    double p50() const;
    double p90() const;
    double p99() const;
    double p999() const;
    double max() const;
};
```

**Алгоритм вычисления перцентиля:**
```
percentile(p):
    IF latencies.empty():
        RETURN 0.0

    sorted = sort(latencies)  // O(n log n)
    index = floor(p * sorted.size())

    IF index >= sorted.size():
        index = sorted.size() - 1

    RETURN sorted[index]
```

**Complexity:**
- `add`: O(1) амортизированная
- `percentile`: O(n log n) (сортировка)
- `p50, p90, p99, p999, max`: O(n log n)

### 1.4 OrderTracker (Отслеживание порядка)

**Назначение:** Валидация порядка сообщений от конкретного производителя.

**Определение:**
```cpp
struct OrderTracker {
    std::map<uint8_t, uint64_t> last_sequence;  // msg_type -> last seq_num
    std::atomic<uint64_t> messages_received{0};
    std::atomic<uint64_t> order_violations{0};
    std::mutex tracker_mutex;

    void track(const Message& msg);
    bool is_ordered() const;
};
```

**Алгоритм track:**
```
track(msg):
    messages_received.fetch_add(1, relaxed)

    LOCK(tracker_mutex):
        key = msg.msg_type
        it = last_sequence.find(key)

        IF it != last_sequence.end():
            IF msg.sequence_number <= it->second:
                order_violations.fetch_add(1, relaxed)

        last_sequence[key] = msg.sequence_number
```

**Complexity:**
- `track`: O(log k) где k — количество уникальных типов сообщений
- `is_ordered`: O(1)

### 1.5 SystemStatistics (Глобальная статистика)

**Назначение:** Агрегация статистики со всей системы.

**Определение:**
```cpp
class SystemStatistics {
public:
    // Счетчики сообщений
    std::atomic<uint64_t> messages_produced{0};
    std::atomic<uint64_t> messages_processed{0};
    std::atomic<uint64_t> messages_delivered{0};
    std::atomic<uint64_t> messages_lost{0};

    // Глубины очередей
    std::vector<std::unique_ptr<std::atomic<size_t>>> stage1_queue_depths;
    std::vector<std::unique_ptr<std::atomic<size_t>>> stage2_queue_depths;

    // Статистика задержек
    LatencyStats stage1_latencies;
    LatencyStats processing_latencies;
    LatencyStats stage2_latencies;
    LatencyStats total_latencies;

    // Валидация порядка
    std::vector<std::unique_ptr<OrderTracker>> producer_order_trackers;

    mutable std::mutex latency_mutex;

    SystemStatistics(size_t num_producers, size_t num_processors, size_t num_strategies);

    void record_message_latencies(const Message& msg);
    void track_message_order(const Message& msg);
    void print_current_stats(double elapsed_secs) const;
    void print_final_report(const std::string& scenario, double duration_secs) const;
    bool validate() const;
    uint64_t total_order_violations() const;
};
```

**Sampling стратегия:**
```cpp
void record_message_latencies(const Message& msg) {
    // Записываем только каждое 1000-е сообщение
    if (msg.sequence_number % 1000 != 0) {
        return;
    }

    std::lock_guard<std::mutex> lock(latency_mutex);
    stage1_latencies.add(msg.stage1_latency_us());
    processing_latencies.add(msg.processing_latency_us());
    stage2_latencies.add(msg.stage2_latency_us());
    total_latencies.add(msg.end_to_end_latency_us());
}
```

---

## 2. АЛГОРИТМЫ КОМПОНЕНТОВ

### 2.1 Producer (Производитель)

**Псевдокод основного цикла:**
```
Producer::run(running, duration_secs):
    interval_ns = 10^9 / messages_per_sec
    start_time = current_time()
    next_send_time = start_time

    WHILE running AND (current_time() - start_time < duration_secs):
        // Генерация типа сообщения
        msg_type = generate_message_type()

        // Создание сообщения
        msg = Message::create(msg_type, id_, sequence_number_)
        sequence_number_ += 1

        // Отправка с backpressure handling
        WHILE NOT output_queue_.try_push(msg):
            __builtin_ia32_pause()

        stats_.messages_produced.fetch_add(1, relaxed)

        // Контроль скорости
        next_send_time += interval_ns
        WHILE current_time() < next_send_time:
            sleep_nanoseconds(100)  // Короткий sleep для точности
```

**Генерация типа сообщения:**
```
generate_message_type():
    // Используем discrete_distribution для вероятностного выбора
    index = type_distribution_(rng_)
    RETURN msg_types_[index]
```

**Анализ сложности:**
- **Временная**: O(1) на сообщение
- **Пространственная**: O(1)
- **Throughput**: Ограничен `messages_per_sec` конфигурацией

### 2.2 Stage1Router (Маршрутизатор 1-й стадии)

**Псевдокод основного цикла:**
```
Stage1Router::run(running):
    WHILE running:
        message_processed = false

        // Читаем из всех входных очередей (round-robin)
        FOR i FROM 0 TO input_queues_.size()-1:
            IF input_queues_[i].try_pop(msg):
                msg.stage1_entry_ns = current_timestamp()

                processor_id = select_processor(msg.msg_type)

                msg.stage1_exit_ns = current_timestamp()

                // Отправка с backpressure
                WHILE NOT output_queues_[processor_id].try_push(msg):
                    __builtin_ia32_pause()

                message_processed = true
                BREAK  // Переход к следующей итерации внешнего цикла

        // Если ничего не обработали, hint CPU
        IF NOT message_processed:
            __builtin_ia32_pause()
```

**Алгоритм select_processor:**
```
select_processor(msg_type):
    processors = routing_table_[msg_type]

    IF processors.empty():
        THROW error("No processor for msg_type")

    IF processors.size() == 1:
        RETURN processors[0]  // Детерминированная маршрутизация
    ELSE:
        // Round-robin балансировка
        counter = rr_counters_[msg_type].fetch_add(1, relaxed)
        index = counter % processors.size()
        RETURN processors[index]
```

**Анализ сложности:**
- **Временная**: O(N) на итерацию, где N — количество производителей
- **Пространственная**: O(M) для таблицы маршрутизации, где M — количество типов
- **Latency**: ~100-200ns (table lookup + timestamps)

### 2.3 Processor (Процессор)

**Псевдокод основного цикла:**
```
Processor::run(running):
    WHILE running:
        IF input_queue_.try_pop(msg):
            msg.processing_entry_ns = current_timestamp()

            // Симуляция обработки
            delay_ns = get_processing_time(msg.msg_type)
            start = current_timestamp()
            WHILE (current_timestamp() - start) < delay_ns:
                __builtin_ia32_pause()

            // Добавление метаданных
            msg.processor_id = id_
            msg.processing_ts_ns = current_timestamp()
            msg.processing_exit_ns = current_timestamp()

            // Отправка
            WHILE NOT output_queue_.try_push(msg):
                __builtin_ia32_pause()

            stats_.messages_processed.fetch_add(1, relaxed)
        ELSE:
            __builtin_ia32_pause()
```

**get_processing_time:**
```
get_processing_time(msg_type):
    it = processing_times_.find(msg_type)
    IF it != processing_times_.end():
        RETURN it->second
    ELSE:
        RETURN 100  // Default 100ns
```

**Анализ сложности:**
- **Временная**: O(1) + O(delay) где delay — симулированное время обработки
- **Пространственная**: O(1)
- **Latency**: Конфигурируемая (50ns - 2000ns)

### 2.4 Stage2Router (Маршрутизатор 2-й стадии)

**Псевдокод основного цикла:**
```
Stage2Router::run(running):
    WHILE running:
        message_processed = false

        FOR i FROM 0 TO input_queues_.size()-1:
            IF input_queues_[i].try_pop(msg):
                msg.stage2_entry_ns = current_timestamp()

                strategy_id = routing_table_[msg.msg_type]

                msg.stage2_exit_ns = current_timestamp()

                WHILE NOT output_queues_[strategy_id].try_push(msg):
                    __builtin_ia32_pause()

                message_processed = true
                BREAK

        IF NOT message_processed:
            __builtin_ia32_pause()
```

**Анализ сложности:**
- **Временная**: O(M) на итерацию, где M — количество процессоров
- **Пространственная**: O(K) для таблицы маршрутизации, где K — количество типов
- **Latency**: ~100-200ns (table lookup + timestamps)

### 2.5 Strategy (Стратегия)

**Псевдокод основного цикла:**
```
Strategy::run(running):
    WHILE running:
        IF input_queue_.try_pop(msg):
            // Валидация порядка
            stats_.track_message_order(msg)

            // Запись задержек (с sampling)
            stats_.record_message_latencies(msg)

            // Симуляция обработки
            start = current_timestamp()
            WHILE (current_timestamp() - start) < processing_time_ns_:
                __builtin_ia32_pause()

            stats_.messages_delivered.fetch_add(1, relaxed)
        ELSE:
            __builtin_ia32_pause()
```

**Анализ сложности:**
- **Временная**: O(log T) для track (T — типов), O(1) для остального
- **Пространственная**: O(1)
- **Latency**: O(processing_time_ns)

---

## 3. LOCK-FREE АЛГОРИТМЫ

### 3.1 SPSCQueue::try_push

**Псевдокод:**
```
try_push(item):
    current_tail = tail_.load(memory_order_relaxed)
    next_tail = (current_tail + 1) & (Capacity - 1)

    // Проверка переполнения
    IF next_tail == head_.load(memory_order_acquire):
        RETURN false

    // Запись элемента
    buffer_[current_tail] = item

    // Публикация нового tail
    tail_.store(next_tail, memory_order_release)
    RETURN true
```

**Обоснование memory ordering:**

1. **`tail_.load(relaxed)`**:
   - Producer единственный писатель в `tail_`
   - Не требуется синхронизация для чтения собственных записей

2. **`head_.load(acquire)`**:
   - Синхронизация с consumer's `head_.store(release)` в `try_pop`
   - Ensures visibility: Если consumer освободил слот, producer увидит это

3. **`tail_.store(release)`**:
   - Публикация записанного элемента для consumer
   - Ensures: Записи в `buffer_` видны consumer до чтения нового `tail_`

**Happens-Before отношения:**
```
Producer:                        Consumer:
buffer_[i] = item    (1)
tail_.store(release) (2) ──────► tail_.load(acquire) (3)
                                 item = buffer_[i]  (4)

(1) happens-before (2) (program order)
(2) synchronizes-with (3) (release-acquire)
(3) happens-before (4) (program order)
=> (1) happens-before (4)
```

**Proof of correctness:**

**Invariant 1**: Если `try_push` возвращает `true`, элемент будет виден consumer.
- Доказательство: `tail_.store(release)` гарантирует видимость записи в `buffer_` для consumer, который читает `tail_` с `acquire`.

**Invariant 2**: Переполнение очереди детектируется корректно.
- Доказательство: `head_.load(acquire)` синхронизирован с `head_.store(release)` в `try_pop`, поэтому producer видит актуальное состояние освобождения слотов.

### 3.2 SPSCQueue::try_pop

**Псевдокод:**
```
try_pop(item):
    current_head = head_.load(memory_order_relaxed)

    // Проверка пустоты
    IF current_head == tail_.load(memory_order_acquire):
        RETURN false

    // Чтение элемента
    item = buffer_[current_head]

    // Освобождение слота
    head_.store((current_head + 1) & (Capacity - 1), memory_order_release)
    RETURN true
```

**Обоснование memory ordering:**

1. **`head_.load(relaxed)`**:
   - Consumer единственный писатель в `head_`

2. **`tail_.load(acquire)`**:
   - Синхронизация с producer's `tail_.store(release)` в `try_push`
   - Ensures: Элемент в `buffer_` записан до чтения

3. **`head_.store(release)`**:
   - Публикация освобождения слота для producer
   - Ensures: Producer увидит новый `head_` при проверке переполнения

**Happens-Before отношения:**
```
Producer:                        Consumer:
buffer_[i] = item       (1)
tail_.store(release)    (2) ──────► tail_.load(acquire) (3)
                                    item = buffer_[i]  (4)
                                    head_.store(release) (5)
                     ◄────────────  head_.load(acquire) (в следующем push)

(1) happens-before (2)
(2) synchronizes-with (3)
(3) happens-before (4)
(4) happens-before (5)
(5) synchronizes-with (head_.load(acquire) в push)
```

**Proof of correctness:**

**Invariant 1**: Если `try_pop` возвращает `true`, элемент корректно прочитан.
- Доказательство: `tail_.load(acquire)` синхронизирован с `tail_.store(release)`, гарантируя видимость записи в `buffer_`.

**Invariant 2**: Consumer не читает дважды один элемент.
- Доказательство: `head_` увеличивается только consumer, и только после успешного чтения.

**Invariant 3**: Consumer не читает "мусор".
- Доказательство: Чтение происходит только если `head_ != tail_`, что гарантирует наличие элемента.

### 3.3 Доказательство Lock-Freedom

**Определение Lock-Freedom:**
Алгоритм lock-free, если при любом выполнении хотя бы один поток гарантированно делает progress в конечное время.

**Доказательство для SPSCQueue:**

1. **try_push (producer)**:
   - **Случай 1**: Очередь не полная → push успешен за O(1) (finite time)
   - **Случай 2**: Очередь полная → возврат `false` за O(1)
   - **Вывод**: Producer всегда делает progress (либо push, либо знание о полноте)

2. **try_pop (consumer)**:
   - **Случай 1**: Очередь не пустая → pop успешен за O(1)
   - **Случай 2**: Очередь пустая → возврат `false` за O(1)
   - **Вывод**: Consumer всегда делает progress

3. **Отсутствие блокировок**:
   - Нет `while` циклов внутри `try_push`/`try_pop`
   - Нет зависимости от действий другого потока для завершения операции

4. **Гарантия progress**:
   - В любой момент времени либо producer, либо consumer (или оба) могут выполнить свою операцию за конечное время
   - Это соответствует определению lock-freedom

**Вывод**: SPSCQueue является lock-free структурой данных.

---

## 4. АЛГОРИТМЫ ОБРАБОТКИ BACKPRESSURE

### 4.1 Busy-Wait при переполнении очереди

**Псевдокод:**
```
send_message_with_backpressure(queue, msg):
    WHILE NOT queue.try_push(msg):
        __builtin_ia32_pause()
        // Опционально: можно добавить счетчик попыток для мониторинга
```

**Обоснование:**
- **Простота**: Нет необходимости в сложных механизмах синхронизации
- **Низкая задержка**: Немедленная реакция на освобождение места в очереди
- **Естественное регулирование**: Медленный потребитель автоматически замедляет производителя

**Trade-offs:**
- ✅ **Pros**: Минимальная latency (<< 1μs)
- ❌ **Cons**: 100% CPU usage во время ожидания

**Альтернативы:**
1. **Exponential backoff**: Увеличение интервала между попытками
   ```
   delay = initial_delay
   WHILE NOT queue.try_push(msg):
       sleep(delay)
       delay = min(delay * 2, max_delay)
   ```
   - Pros: Снижение CPU usage
   - Cons: Увеличение latency

2. **Yield-based waiting**:
   ```
   WHILE NOT queue.try_push(msg):
       std::this_thread::yield()
   ```
   - Pros: Отдача CPU другим потокам
   - Cons: Контекстные переключения увеличивают latency

**Выбор**: Busy-wait выбран для минимизации latency в HFT-подобной системе.

### 4.2 Каскадное распространение backpressure

**Схема:**
```
Producer
  ↓ (backpressure если stage1_input_queue полная)
Stage1 Router
  ↓ (backpressure если processor_queue полная)
Processor
  ↓ (backpressure если stage2_input_queue полная)
Stage2 Router
  ↓ (backpressure если strategy_queue полная)
Strategy
```

**Эффект:**
- Медленная Strategy → заполнение strategy_queue
- Stage2 Router замедляется → заполнение processor_to_stage2_queues
- Processors замедляются → заполнение stage1_to_processor_queues
- Stage1 Router замедляется → заполнение producer_queues
- Producers замедляются → естественное снижение скорости генерации

**Плюсы:**
- Автоматическое регулирование без явного управления
- Нет потери сообщений
- Система остается в валидном состоянии

**Минусы:**
- Один медленный компонент может замедлить всю систему
- Требуется достаточно большие очереди для буферизации всплесков

---

## 5. АЛГОРИТМЫ ВАЛИДАЦИИ И МОНИТОРИНГА

### 5.1 Валидация порядка сообщений

**Алгоритм OrderTracker::track:**
```
track(msg):
    messages_received++

    LOCK(tracker_mutex):
        key = msg.msg_type

        IF last_sequence.contains(key):
            expected_seq = last_sequence[key] + 1

            IF msg.sequence_number < expected_seq:
                order_violations++
                LOG("Ordering violation detected: "
                    "producer={}, type={}, "
                    "expected>={}, got={}")
            ELSE IF msg.sequence_number > expected_seq:
                // Возможны пропуски, но не reordering
                // В системе без потерь это не должно происходить
                PASS

        last_sequence[key] = msg.sequence_number
```

**Обоснование условия `msg.seq <= last_seq`:**
- Если новый seq меньше или равен последнему, значит произошло переупорядочивание
- Если новый seq больше, порядок соблюден (возможны пропуски, но не reordering)

**Complexity:** O(log T) где T — количество типов сообщений

### 5.2 Вычисление перцентилей

**Алгоритм:**
```
percentile(p):
    n = latencies.size()
    IF n == 0:
        RETURN 0.0

    sorted = sort(latencies)  // O(n log n)

    index = floor(p * n)
    IF index >= n:
        index = n - 1

    RETURN sorted[index]
```

**Примеры:**
- `p50`: 50-й перцентиль (медиана)
  - `index = 0.5 * 1000 = 500` → sorted[500]
- `p99`: 99-й перцентиль
  - `index = 0.99 * 1000 = 990` → sorted[990]

**Complexity:** O(n log n) из-за сортировки

**Оптимизация:** Использовать `std::nth_element` для O(n) для одного перцентиля:
```cpp
double percentile(double p) const {
    if (latencies.empty()) return 0.0;

    std::vector<double> copy = latencies;
    size_t index = static_cast<size_t>(p * copy.size());
    if (index >= copy.size()) index = copy.size() - 1;

    std::nth_element(copy.begin(), copy.begin() + index, copy.end());
    return copy[index];
}
```

### 5.3 Sampling для снижения overhead

**Стратегия:**
```
record_latency_with_sampling(msg):
    IF msg.sequence_number % SAMPLING_RATE != 0:
        RETURN  // Skip

    LOCK(latency_mutex):
        latencies.add(msg.latency())
```

**Параметр:** `SAMPLING_RATE = 1000`

**Обоснование:**
- При 10M сообщений/сек, без sampling:
  - 10M записей латентности/сек
  - Огромная contention на mutex
  - Значительный overhead памяти

- С sampling 1:1000:
  - 10K записей/сек
  - Минимальная contention
  - Статистически значимая выборка

**Статистическая значимость:**
- Для 10-секундного теста с 40M сообщений:
  - Без sampling: 40M точек данных
  - С sampling: 40K точек данных
  - 40K достаточно для надежной оценки перцентилей

---

## 6. АЛГОРИТМЫ УПРАВЛЕНИЯ ВРЕМЕНЕМ

### 6.1 Контроль скорости генерации (Producer)

**Алгоритм:**
```
control_rate(messages_per_sec):
    interval_ns = 10^9 / messages_per_sec
    next_send_time = current_time_ns()

    LOOP:
        // Генерация и отправка сообщения
        send_message()

        // Обновление целевого времени
        next_send_time += interval_ns

        // Ожидание до целевого времени
        WHILE current_time_ns() < next_send_time:
            // Короткий sleep для снижения CPU usage
            sleep_nanoseconds(min(100, next_send_time - current_time_ns()))
```

**Обоснование:**
- **Абсолютное время vs относительное**: Используем абсолютное время для предотвращения дрифта
- **Короткий sleep**: Баланс между точностью и CPU usage

**Точность:**
- Цель: `messages_per_sec` = 1,000,000 → interval = 1000ns
- Достижимая точность: ±50ns (зависит от разрешения таймера)
- Погрешность: <5%

### 6.2 Измерение задержек

**Алгоритм:**
```
measure_stage_latency(entry_field, exit_field):
    msg.entry_field = current_timestamp_ns()

    // ... обработка ...

    msg.exit_field = current_timestamp_ns()

    latency_us = (msg.exit_field - msg.entry_field) / 1000.0
```

**Источник времени:**
```cpp
uint64_t get_timestamp_ns() {
    return std::chrono::duration_cast<std::chrono::nanoseconds>(
        std::chrono::high_resolution_clock::now().time_since_epoch()
    ).count();
}
```

**Разрешение:**
- `high_resolution_clock`: Обычно ~1ns разрешение на современных системах
- Достаточно для измерения микросекундных задержек

**Накладные расходы:**
- Вызов `std::chrono::high_resolution_clock::now()`: ~20-50ns
- 6 вызовов на сообщение: ~120-300ns overhead
- Приемлемо для системы с микросекундными задержками

---

## 7. ОПТИМИЗАЦИОННЫЕ ТЕХНИКИ

### 7.1 Битовые операции для модуло

**Стандартный подход:**
```cpp
next_index = (current_index + 1) % Capacity;  // Дорого: деление
```

**Оптимизированный подход (Capacity = степень 2):**
```cpp
next_index = (current_index + 1) & (Capacity - 1);  // Дешево: битовое AND
```

**Обоснование:**
Для степени 2: `x % Capacity == x & (Capacity - 1)`

**Пример:**
```
Capacity = 8 = 0b1000
Capacity - 1 = 7 = 0b0111

x = 10 = 0b1010
x % 8 = 2
x & 7 = 0b1010 & 0b0111 = 0b0010 = 2  ✓
```

**Выигрыш:**
- Деление: ~10-40 циклов CPU
- Битовое AND: 1 цикл CPU
- Speedup: 10-40×

### 7.2 Cache-line выравнивание

**Проблема false sharing:**
```cpp
struct Bad {
    std::atomic<size_t> head_;  // Offset 0
    std::atomic<size_t> tail_;  // Offset 8
    // Оба в одной cache line!
};
```

**Решение:**
```cpp
struct Good {
    alignas(64) std::atomic<size_t> head_;  // Offset 0
    alignas(64) std::atomic<size_t> tail_;  // Offset 64
    // В разных cache lines!
};
```

**Выигрыш:**
- Без выравнивания: Каждое обновление `head_` инвалидирует cache line с `tail_`
- С выравниванием: `head_` и `tail_` в разных cache lines, нет false sharing
- Speedup: 2-10× в зависимости от интенсивности доступа

### 7.3 Memory prefetching

**Явный prefetch (опционально):**
```cpp
void prefetch_next_messages(Queue& queue, size_t count) {
    for (size_t i = 0; i < count; ++i) {
        __builtin_prefetch(&queue.buffer_[(queue.head_ + i) & (Capacity - 1)]);
    }
}
```

**Эффект:**
- Загрузка данных в кеш до фактического доступа
- Снижение cache miss latency
- Особенно полезно для больших сообщений

---

## 8. COMPLEXITY ANALYSIS

### 8.1 Временная сложность операций

| Операция | Worst-case | Amortized | Примечание |
|----------|-----------|----------|-----------|
| SPSCQueue::try_push | O(1) | O(1) | Atomic операции |
| SPSCQueue::try_pop | O(1) | O(1) | Atomic операции |
| Producer::generate_msg | O(1) | O(1) | RNG + discrete dist |
| Stage1Router::route | O(N) | O(1) | N входных очередей |
| Processor::process | O(1) + O(D) | - | D = delay time |
| Stage2Router::route | O(M) | O(1) | M процессоров |
| Strategy::validate_order | O(log T) | O(log T) | T типов сообщений |
| LatencyStats::percentile | O(n log n) | - | Сортировка |

### 8.2 Пространственная сложность

| Структура | Размер | Количество | Общее |
|-----------|--------|------------|-------|
| Message | 96 bytes | N (в полете) | 96N |
| SPSCQueue | 96 * 65536 | P+M+M+S | ~6.3MB × (P+M+M+S) |
| OrderTracker | O(T) | P | O(PT) |
| LatencyStats | O(S) | 4 | O(S) |
| Routing tables | O(T) | 2 | O(T) |

Где:
- P = количество производителей
- M = количество процессоров
- S = количество стратегий
- T = количество типов сообщений
- N = количество сообщений в полете

**Пример для baseline:**
- P=4, M=4, S=3, T=4
- Очереди: 6.3MB × (4+4+4+3) = ~95MB
- OrderTrackers: 4 × 4 × 8 bytes ≈ 128 bytes
- LatencyStats: ~40K × 8 bytes = 320KB
- **Total**: ~100MB

---

**Конец документа**
